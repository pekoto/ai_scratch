{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "935d4516-06ed-4057-aea8-edfba85cd216",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64103cfb-0802-43d3-9395-f1f84b2b1dd3",
   "metadata": {},
   "source": [
    "_Heavily cribbed from https://github.com/gkamradt/langchain-tutorials/_\n",
    "\n",
    "## Concepts\n",
    "\n",
    "> LangChain is a framework for developing apps with language models.\n",
    "\n",
    "It makes development easier in two ways:\n",
    "\n",
    "1. __Integration__: Links external data, such as files, other apps, or APIs, with the LLM\n",
    "2. __Agency__: Allows LLMs to interact with its environment via decision making. Use LLMs to decide which action to take next.\n",
    "\n",
    "## References\n",
    "\n",
    "[Tutorials](https://python.langchain.com/v0.1/docs/additional_resources/tutorials/)\n",
    "[Use Cases](https://python.langchain.com/v0.1/docs/use_cases/)\n",
    "\n",
    "* Q&A with RAG\n",
    "* Extracting structured output\n",
    "* Chatbots\n",
    "* Tool use and agents\n",
    "* Query analysis\n",
    "* Q&A over SQL + CSV\n",
    "* More\n",
    "\n",
    "[Tool List](https://python.langchain.com/v0.1/docs/integrations/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234717c-0628-4416-ad12-ca28165d0f3c",
   "metadata": {},
   "source": [
    "## Components\n",
    "\n",
    "### 1. Schema: The Building Blocks for working with LLMs\n",
    "\n",
    "#### 1.1 Text\n",
    "\n",
    "#### 1.2 Chat Messages\n",
    "\n",
    "Like text, but with a message type:\n",
    "\n",
    "* System: Background context\n",
    "* Human\n",
    "* AI\n",
    "\n",
    "```python\n",
    "%pip install python-dotenv\n",
    "%pip install langchain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key=os.getenv('OPENAI_API_KEY', 'YourAPIKey')\n",
    "\n",
    "%pip install openai\n",
    "%pip install langchain-community langchain-core\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# This it the language model we'll use. We'll talk about what we're doing below in the next section\n",
    "chat = ChatOpenAI(temperature=.7, openai_api_key=openai_api_key)\n",
    "```\n",
    "\n",
    "```\n",
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
    "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "> AIMessage(content='You could try a caprese salad with fresh tomatoes, mozzarella, and basil.')\n",
    "\n",
    "You can also pass more chat history w/ responses from the AI\n",
    "\n",
    "```python\n",
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
    "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
    "        AIMessage(content=\"You should go to Nice, France\"),\n",
    "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
    "    ])\n",
    "```\n",
    "\n",
    "#### 1.3 Documents\n",
    "\n",
    "An object that holds text and metadata about the text.\n",
    "\n",
    "```python\n",
    "from langchain.schema import Document\n",
    "\n",
    "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
    "         metadata={\n",
    "             'my_document_id' : 234234,\n",
    "             'my_document_source' : \"The LangChain Papers\",\n",
    "             'my_document_create_time' : 1680013019\n",
    "         })\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af88ece7-91db-4fd2-8955-27cb1e858346",
   "metadata": {},
   "source": [
    "### 2. Models\n",
    "\n",
    "The models interface to the AI brains.\n",
    "\n",
    "* __2.1 Language Model__: Text in --> Text out\n",
    "* __2.2 Chat Model__: Takes a series of messages --> return message output\n",
    "* __2.3 Function Calling Model__: Fine-tuned to give structured data output. Useful when making an API call to an external service or doing data extraction.\n",
    "```python\n",
    "chat = ChatOpenAI(model='gpt-3.5-turbo-0613', temperature=1, openai_api_key=openai_api_key)\n",
    "\n",
    "output = chat(messages=\n",
    "     [\n",
    "         SystemMessage(content=\"You are an helpful AI bot\"),\n",
    "         HumanMessage(content=\"What’s the weather like in Boston right now?\")\n",
    "     ],\n",
    "     functions=[{\n",
    "         \"name\": \"get_current_weather\",\n",
    "         \"description\": \"Get the current weather in a given location\",\n",
    "         \"parameters\": {\n",
    "             \"type\": \"object\",\n",
    "             \"properties\": {\n",
    "                 \"location\": {\n",
    "                     \"type\": \"string\",\n",
    "                     \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                 },\n",
    "                 \"unit\": {\n",
    "                     \"type\": \"string\",\n",
    "                     \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                 }\n",
    "             },\n",
    "             \"required\": [\"location\"]\n",
    "         }\n",
    "     }\n",
    "     ]\n",
    ")\n",
    "output\n",
    "```\n",
    "\n",
    "```\n",
    "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_weather', 'arguments': '{\\n  \"location\": \"Boston, MA\"\\n}'}})\n",
    "```\n",
    "\n",
    "* __2.4 Text Embedding__: Turns the text into a vector, useful when comparing text.\n",
    "\n",
    "```python\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "text = \"Hi! It's time for the beach\"\n",
    "text_embedding = embeddings.embed_query(text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b7781-305f-446b-86e1-018c13d45475",
   "metadata": {},
   "source": [
    "### 3. Prompts\n",
    "\n",
    "#### 3.1 Prompts\n",
    "\n",
    "What you pass to the underlying model\n",
    "\n",
    "```python\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "# I like to use three double quotation marks for my prompts because it's easier to read\n",
    "prompt = \"\"\"\n",
    "Today is Monday, tomorrow is Wednesday.\n",
    "\n",
    "What is wrong with that statement?\n",
    "\"\"\"\n",
    "\n",
    "print(llm(prompt))\n",
    "```\n",
    " \n",
    "#### 3.2 Prompt Templates\n",
    "\n",
    "An object that helps create prompts based on a combination of user input, other non-static information and a fixed template string.\n",
    "\n",
    "Think of it as an f-string in python but for prompts\n",
    "\n",
    "Advanced: Check out LangSmithHub(https://smith.langchain.com/hub) for many more communit prompt templates\n",
    "\n",
    "```python\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "# Notice \"location\" below, that is a placeholder for another value later\n",
    "template = \"\"\"\n",
    "I really want to travel to {location}. What should I do there?\n",
    "\n",
    "Respond in one short sentence\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"location\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(location='Rome')\n",
    "\n",
    "print (f\"Final Prompt: {final_prompt}\")\n",
    "print (\"-----------\")\n",
    "print (f\"LLM Output: {llm(final_prompt)}\")\n",
    "```\n",
    "\n",
    "#### 3.3 Example Selectors\n",
    "\n",
    "An easy way to select from a series of examples that allow you to dynamic place in-context information into your prompt. Often used when your task is nuanced or you have a large list of examples.\n",
    "\n",
    "```python\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Example Input: {input}\\nExample Output: {output}\",\n",
    ")\n",
    "\n",
    "# Examples of locations that nouns are found\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
    "    {\"input\": \"pilot\", \"output\": \"plane\"},\n",
    "    {\"input\": \"driver\", \"output\": \"car\"},\n",
    "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
    "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
    "]\n",
    "\n",
    "# SemanticSimilarityExampleSelector will select examples that are similar to your input by semantic meaning\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # This is the list of examples available to select from.\n",
    "    examples, \n",
    "    \n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(openai_api_key=openai_api_key), \n",
    "    \n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    Chroma, \n",
    "    \n",
    "    # This is the number of examples to produce.\n",
    "    k=2\n",
    ")\n",
    "\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    # The object that will help select examples\n",
    "    example_selector=example_selector,\n",
    "    \n",
    "    # Your prompt\n",
    "    example_prompt=example_prompt,\n",
    "    \n",
    "    # Customizations that will be added to the top and bottom of your prompt\n",
    "    prefix=\"Give the location an item is usually found in\",\n",
    "    suffix=\"Input: {noun}\\nOutput:\",\n",
    "    \n",
    "    # What inputs your prompt will receive\n",
    "    input_variables=[\"noun\"],\n",
    ")\n",
    "\n",
    "# Select a noun!\n",
    "my_noun = \"plant\"\n",
    "# my_noun = \"student\"\n",
    "\n",
    "print(similar_prompt.format(noun=my_noun))\n",
    "\n",
    "```\n",
    "Give the location an item is usually found in\n",
    "\n",
    "Example Input: tree\n",
    "Example Output: ground\n",
    "\n",
    "Example Input: bird\n",
    "Example Output: nest\n",
    "\n",
    "Input: plant\n",
    "Output:\n",
    "```\n",
    "\n",
    "```python\n",
    "llm(similar_prompt.format(noun=my_noun))\n",
    "```\n",
    "\n",
    "\n",
    "`pot`\n",
    "\n",
    "\n",
    "#### 3.4 Output Parsers: Prompt Instructions & String Parsing\n",
    "\n",
    "A helpful way to format the output of a model. Usually used for structured output. LangChain has a bunch more output parsers listed on their documentation.\n",
    "\n",
    "1. __Format Instructions__: A autogenerated prompt that tells the LLM how to format it's response based off your desired result\n",
    "2. __Parser__: A method which will extract your model's text output into a desired structure (usually json)\n",
    "\n",
    "##### 3.5 Output Parsers: OpenAI Functions\n",
    "\n",
    "When OpenAI released function calling, the game changed. This is recommended method when starting out.\n",
    "\n",
    "They trained models specifically for outputing structured data. It became super easy to specify a Pydantic schema and get a structured output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26357e5-8e8e-4fe6-9e04-63911ad0d42e",
   "metadata": {},
   "source": [
    "### 4. Indexes\n",
    "\n",
    "Indexes are used to structure documents so LLMs can work with them.\n",
    "\n",
    "#### 4.1 Document Loaders\n",
    "\n",
    "Allow you to import documents from other sources. E.g., hacker news, wiki, web pages.\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\n",
    "    \"http://www.paulgraham.com/\",\n",
    "]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "data[0].page_content\n",
    "```\n",
    "\n",
    "#### 4.2 Text Splitters\n",
    "\n",
    "Often times your document is too long (like a book) for your LLM or Vector DB. You need to split it up into chunks. Text splitters help with this.\n",
    "\n",
    "```python\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# This is a long document we can split up.\n",
    "with open('data/PaulGrahamEssays/worked.txt') as f:\n",
    "    pg_work = f.read()\n",
    "    \n",
    "# 1 Document\n",
    "print (f\"You have {len([pg_work])} document\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap  = 20,\n",
    ")\n",
    "\n",
    "# 610 Documents\n",
    "texts = text_splitter.create_documents([pg_work])\n",
    "```\n",
    "\n",
    "#### 4.3 Retrievers\n",
    "\n",
    "An easy way to combine documents with large language models.\n",
    "\n",
    "There are many different types of retrievers, the most widely supported is the VectoreStoreRetriever\n",
    "\n",
    "```python\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader('data/PaulGrahamEssays/worked.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Get embedding engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Embedd your texts\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# Init your retriever. Asking for just 1 document back\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "docs = retriever.get_relevant_documents(\"what types of things did the author want to build?\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n\".join([x.page_content[:200] for x in docs[:2]]))\n",
    "```\n",
    "\n",
    "#### 4.4 VectorStores\n",
    "Databases to store vectors. Most popular ones are [Pinecone](https://www.pinecone.io/) & [Weaviate](https://weaviate.io/). More examples on OpenAIs [retriever documentation](https://github.com/openai/chatgpt-retrieval-plugin#choosing-a-vector-database). [Chroma](https://www.trychroma.com/) & [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) are easy to work with locally.\n",
    "\n",
    "Conceptually, think of them as tables w/ a column for embeddings (vectors) and a column for metadata.\n",
    "\n",
    "Example\n",
    "\n",
    "| Embedding      | Metadata |\n",
    "| ----------- | ----------- |\n",
    "| [-0.00015641732898075134, -0.003165106289088726, ...]      | {'date' : '1/2/23}       |\n",
    "| [-0.00035465431654651654, 1.4654131651654516546, ...]   | {'date' : '1/3/23}        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d31c3-01c7-4e4d-827d-32ecd3640704",
   "metadata": {},
   "source": [
    "### 5. Memory\n",
    "\n",
    "Helping LLMs remember information.\n",
    "\n",
    "Memory is a bit of a loose term. It could be as simple as remembering information you've chatted about in the past or more complicated information retrieval.\n",
    "\n",
    "There are many types of memory, explore [the documentation](https://python.langchain.com/en/latest/modules/memory/how_to_guides.html) to see which one fits your use case.\n",
    "\n",
    "#### 5.1 Chat Message History"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddad1c7-0f8b-44fd-9e61-0b96a0c9f71a",
   "metadata": {},
   "source": [
    "### 6. Chains\n",
    "\n",
    "Combining different LLM calls and action automatically\n",
    "\n",
    "Ex: Summary #1, Summary #2, Summary #3 > Final Summary\n",
    "\n",
    "Check out [this video](https://www.youtube.com/watch?v=f9_BWhCI4Zo&t=2s) explaining different summarization chain types\n",
    "\n",
    "There are [many applications of chains](https://python.langchain.com/en/latest/modules/chains/how_to_guides.html) search to see which are best for your use case.\n",
    "\n",
    "#### 6.1 Simple Sequential Chains\n",
    "\n",
    "Easy chains where you can use the output of an LLM as an input into another. Good for breaking up tasks (and keeping your LLM focused)\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=1, openai_api_key=openai_api_key)\n",
    "\n",
    "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "\n",
    "# Holds my 'location' chain\n",
    "location_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "\n",
    "# Holds my 'meal' chain\n",
    "meal_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)\n",
    "\n",
    "review = overall_chain.run(\"Rome\")\n",
    "```\n",
    "\n",
    "```\n",
    "> Entering new SimpleSequentialChain chain...\n",
    "\n",
    "A classic dish from Rome is Spaghetti alla Carbonara, featuring egg, Parmesan cheese, black pepper, and pancetta or guanciale.\n",
    "\n",
    "Ingredients:\n",
    "- 8oz spaghetti \n",
    "- 4 tablespoons olive oil\n",
    "- 4oz diced pancetta or guanciale\n",
    "- 2 cloves garlic, minced\n",
    "- 2 eggs, lightly beaten\n",
    "- 2 tablespoons parsley, chopped \n",
    "- ½ cup grated Parmesan \n",
    "- Salt and black pepper to taste\n",
    "\n",
    "Instructions:\n",
    "1. Bring a pot of salted water to a boil and add the spaghetti. Cook according to package directions. \n",
    "2. Meanwhile, add the olive oil to a large skillet over medium-high heat. Add the diced pancetta and garlic, and cook until pancetta is browned and garlic is fragrant.\n",
    "3. In a medium bowl, whisk together the eggs, parsley, Parmesan, and salt and pepper.\n",
    "4. Drain the cooked spaghetti and add it to the skillet with the pancetta and garlic. Remove from heat and pour the egg mixture over the spaghetti, stirring to combine. \n",
    "5. Serve the spaghetti alla carbonara with additional Parmesan cheese and black pepper.\n",
    "\n",
    "> Finished chain.\n",
    "```\n",
    "\n",
    "#### 6.2 Summarization Chain\n",
    "\n",
    "Easily run through long numerous documents and get a summary. Check out [this video](https://www.youtube.com/watch?v=f9_BWhCI4Zo) for other chain types besides map-reduce.\n",
    "\n",
    "```python\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader('data/PaulGrahamEssays/disc.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# There is a lot of complexity hidden in this one line. I encourage you to check out the video above for more detail\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
    "chain.run(texts)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ccb390-2679-43c7-88a8-6dd03a8b1602",
   "metadata": {},
   "source": [
    "### 7. Agents\n",
    "\n",
    "Official LangChain Documentation describes agents:\n",
    "\n",
    "> Some applications will require not just a predetermined chain of calls to LLMs/other tools, but potentially an **unknown chain** that depends on the user's input. In these types of chains, there is a “agent” which has access to a suite of tools. Depending on the user input, the agent can then **decide which, if any, of these tools to call**.\n",
    "\n",
    "\n",
    "Basically you use the LLM not just for text output, but also for decision making. The coolness and power of this functionality can't be overstated enough.\n",
    "\n",
    "#### 7.1 Agents\n",
    "\n",
    "The language model that drives decision making.\n",
    "\n",
    "Takes an input and returns a response corresponding to an action to take along with an action input.\n",
    "\n",
    "You can see different types of agents (which are better for different use cases) [here](https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html).\n",
    "\n",
    "#### 7.2 Tools\n",
    "\n",
    "The capability of an agent. An abstraction on top of a function that makes it easy for LLMs to interact with it. E.g. Google Search.\n",
    "\n",
    "##### 7.3 Toolkit\n",
    "\n",
    "A group of tools that your agent can select from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd07ce-e6d6-4438-a1a0-78f0a86e1f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
